\section{Design}
	
    In diesem Abschnitt wird der Aufbau des Prototypen erklärt Und die darin verwendeten Technologien vorgestellt. Mann kann den Prototypen in drei wesentliche Teile gliedern.
            
	\begin{description}
		\item[Das Framework] ist vor allem für die Benutzeroberfläche und für das Verarbeiten von Benutzereingaben verantwortlich. Es dient als Rahmen der Applikation und ist für die kommunikation mit dem jeweiligen Betriebssystem zuständig.
        
        \item[Learner und Predictor] sind für den \emph{Natural Language Processing} Teil der Anwendung zuständig. Der \emph{Learner} kann neue Sprachmodelle aus Texten erzeugen. Der \emph{Predictor} kann mit diesen Sprachmodellen Wortlisten liefern. 
        
        \item[Adapter] bilden Signale von verschiedenen Eingabegeräten auf die vom Prototypen definierten Signale ab. Sie ermöglichen es \emph{Plugins} für weitere Eingabegeräte zu schreiben.
	\end{description}
    
	\subsection{Das Framework}
    	Die Software ist in \emph{Python} geschrieben. \emph{Python} scheint eine viel für \emph{Natural Language Processing} verwendete Sprache zu sein. Sucht man z. B. auf \emph{github.com} nach den in \autoref{tab:githubNLP} gezeigten Begriffen, liegt Python als Sprache immer weit vorne.
        
        \begin{figure}[H]
			\centering
                
			\begin{tabular}{ r || c | c | c}
                \diagbox{Sprache}{Suchbegriff} & NLP & Natural Language & Natural Language Processing \\ \hline \hline
                Python & 1168 & 500 & 348\\ \hline
                Java & 740 & 269 & 172\\ \hline
                JavaScript & 135 & 146 & 37 \\ \hline
                Ruby & 103 & 100 & 28 \\ \hline
                C++ & 76  & 45 & 23 \\ \hline
            \end{tabular}
            \caption{Anzahl gefundener Repositories in den top fünf Sprachen auf \texttt{https://github.com/search} (besucht am 02.07.2015)}
			\label{tab:githubNLP}
		\end{figure}
        
        Für die Benutzeroberfläche wird ein \emph{open source framework} mit dem Namen \emph{Kivy} verwendet. Laut der Offiziellen Webseite \parencite{kivy:homepage} laufen mit \emph{Kivy} geschriebene Aplikationen unter Linux, Windows, OS X, Android und iOS. Dazu muss die Applikation für jedes entsprechnende System gepackt werden.
        
        In der \texttt{main.py} Datei wird die \texttt{run} Funktion von \emph{Kivy} aufgerufen. Diese startet die Applikation, setzt \emph{listener} auf die verfügbaren \emph{Adapter} und instanziiert einen \emph{Predictor}.
        
	\subsection{Learner und Predictor}
    
    	Der \emph{Learner} besteht aus zwei speraten Teilen. Sus einem \emph{Tokenizer} und einem \emph{Clusterer}. Der \emph{Tokenizer} hat die Aufgabe, Texte wie sie z.B. in einem Buch zu finden sind, zu bereinigen. Dem \emph{Tokenizer} werden mehrere Textdateien übergeben aus welcher dieser eine einzelne neue Textdatei generiert. Darin befindet sich der bereinigte Text in einer Form wie er von dem \emph{Clusterer} gelesen werden kann.

		Der \emph{Clusterer} liest und analysiert die vom \emph{Tokenizer} generierte Textdatei. Dieser Umweg über eine extra generierte Datei ist nötig, da für den \emph{Clusterer} eine \emph{third party} Lösung verwendet wird. Dies wird in \autoref{sec:thirdTry} genauer beschrieben. In erster Linie gruppiert der \emph{Clusterer} die übergebenen Worte in Klassen und speichert das Ergebniss wieder in mehreren Dateien ab. Die vom \emph{Clusterer} generierten Dateien werden im folgenden \emph{Sprachmodell} genannt.

		Das generieren von \emph{Sprachmodellen} ist nicht Teil der gepackten Applikation. Dazu muss für jedes neue Sprachmodell der \emph{Tokenizer} und der \emph{Clusterer} von Hand aufgerufen werden. Das generierte \emph{Sprachmodell} wird dann in den dafür vorgesehen Ordner in der Applikation gelegt.

		In der laufenden Applikation kann der Nutzer eine Kategorie auswählen. Diese entspricht immer einem \emph{Sprachmodell}. Nach der Auswahl wird wird dieses automatisch von dem \emph{Predictor} geladen. Dieser Prozess wird in \autoref{sec:implemetation-wordPredition} genauer beschrieben. Aufgrund des Sprachmodells wird vom \emph{Predictor} dann eine Wortliste generiert.
        
    \subsection{Adapter}
    
    	Ein \emph{Adapter} besteht aus einer einzigen \emph{Python} Datei mit dem Namen des Gerätes kombiniert mit dem Wort \emph{Adapter}. Jeder \emph{Adapter} muss von der Klasse \texttt{SuperAdaper} erben.

		Jeder neue \emph{Adapter} muss in dem Ordner \texttt{inputAdapters} gespeichert werden. Auserdem muss dieser in der \texttt{\_\_init\_\_.py} im gleichen Ordner importiert und in die Liste \texttt{adapters} eingetragen werden. Durch diesen Prozess wird erreicht, dass für das Hinzufügen von einem \emph{Adapter} nur Änderungen innerhalb eines einzigen Ordners vorgenommen werden müssen.

		\texttt{SuperAdaper} wiederum erbt von \emph{Kivy}'s \texttt{EventDispatcher}.
So ist es einfach innerhalb der Applikation auf Signale zu reagieren.
Singnale sind einfache Strings bestehend aus dem kleingeschribenen Namen des Signals. Ein \emph{Adapter} muss eine statische Funktion \texttt{is\_available()} implementieren, die angibt ob das zum \emph{Adapter} entsprechnde Gerät verfügbar ist. Sollte das nicht der Fall sein wird ein \emph{Adapter} nicht geladen.

		Des weiteren muss ein \emph{Adapter} minnimal die drei Signale \texttt{left}, \texttt{right} und \texttt{enter} senden können. Wenn möglich kann ein Adapter auch noch weitere Signale senden. Mögliche weitere Signale sind: \texttt{up}, \texttt{down}, \texttt{talk} und \texttt{close}.
        
	
    \newpage